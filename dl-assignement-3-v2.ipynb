{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8245488,"sourceType":"datasetVersion","datasetId":4891846},{"sourceId":8255378,"sourceType":"datasetVersion","datasetId":4899019}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jaswanth431/dl-assignement-3-v2?scriptVersionId=175612901\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nimport random","metadata":{"_uuid":"790ab3c6-fa40-4fa9-a2b2-6c9e827583d0","_cell_guid":"25f71506-5c69-4ad9-8ae9-7c3d144e11b6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:22.129408Z","iopub.execute_input":"2024-05-04T10:00:22.129798Z","iopub.status.idle":"2024-05-04T10:00:22.135738Z","shell.execute_reply.started":"2024-05-04T10:00:22.129769Z","shell.execute_reply":"2024-05-04T10:00:22.134768Z"},"scrolled":true,"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n#Global constants\nMAX_LENGTH = 30\nINPUT_MAX_LENGTH = 0\nOUTPUT_MAX_LENGTH = 0\nEND_TOKEN = '>'\nSTART_TOKEN = '<'\nPAD_TOKEN = '_'\nTEACHER_FORCING_RATIO = 0.5","metadata":{"_uuid":"07fa0a9b-3526-4b01-a4f7-2adc2ffaefe3","_cell_guid":"a75f2a15-a2cd-4584-957d-ad804e943d32","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:22.175923Z","iopub.execute_input":"2024-05-04T10:00:22.176463Z","iopub.status.idle":"2024-05-04T10:00:22.181875Z","shell.execute_reply.started":"2024-05-04T10:00:22.176439Z","shell.execute_reply":"2024-05-04T10:00:22.181055Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_train.csv\"\n# test_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_test.csv\"\n# val_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_valid.csv\"\ntrain_csv = \"/kaggle/input/aksh11/aksharantar_sampled/hin/hin_train.csv\"\ntest_csv = \"/kaggle/input/aksh11/aksharantar_sampled/hin/hin_test.csv\"\nval_csv = \"/kaggle/input/aksh11/aksharantar_sampled/hin/hin_valid.csv\"","metadata":{"_uuid":"e4df791b-37bb-4308-8658-588f9f91df28","_cell_guid":"5b0aaf58-1393-4c84-b3b9-39de8905fa0c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:22.222114Z","iopub.execute_input":"2024-05-04T10:00:22.222709Z","iopub.status.idle":"2024-05-04T10:00:22.226799Z","shell.execute_reply.started":"2024-05-04T10:00:22.222668Z","shell.execute_reply":"2024-05-04T10:00:22.225841Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_csv, header=None)\ntrain_source, train_target = train_df[0].to_numpy(), train_df[1].to_numpy();\ntest_df = pd.read_csv(test_csv, header=None)\nval_df = pd.read_csv(val_csv, header=None)\nval_source, val_target = val_df[0].to_numpy(), val_df[1].to_numpy();\n","metadata":{"_uuid":"de579fbe-b990-4a9b-9772-39f6140fb8af","_cell_guid":"96cccdd5-ba57-4899-b0a4-6c89b979a180","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:22.264643Z","iopub.execute_input":"2024-05-04T10:00:22.264922Z","iopub.status.idle":"2024-05-04T10:00:22.363569Z","shell.execute_reply.started":"2024-05-04T10:00:22.264899Z","shell.execute_reply":"2024-05-04T10:00:22.362732Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def add_padding(source_data, MAX_LENGTH):\n    padded_source_strings = []\n    for i in range(len(source_data)):\n        source_str =START_TOKEN+ source_data[i] + END_TOKEN\n        # Truncate or pad source sequence\n        source_str = source_str[:MAX_LENGTH]\n        source_str += PAD_TOKEN * (MAX_LENGTH - len(source_str))\n\n        padded_source_strings.append(source_str)\n        \n    return padded_source_strings\n\n\ndef generate_string_to_sequence(source_data, source_char_index_dict):\n    source_sequences = []\n    for i in range(len(source_data)):\n        source_sequences.append(get_chars(source_data[i], source_char_index_dict))\n    source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=2)\n    return source_sequences\n\n\ndef get_chars(str, char_index_dict):\n    chars_indexes = []\n    for ch in str:\n        chars_indexes.append(char_index_dict[ch])\n    return torch.tensor(chars_indexes, device=device)\n\n\ndef preprocess_data(source_data, target_data):\n    data = {\n        \"source_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"target_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"source_char_index\": {START_TOKEN: 0, END_TOKEN:1, PAD_TOKEN:2},\n        \"source_index_char\": {0:START_TOKEN, 1: END_TOKEN, 2:PAD_TOKEN},\n        \"target_char_index\": {START_TOKEN: 0, END_TOKEN:1, PAD_TOKEN:2},\n        \"target_index_char\": {0:START_TOKEN, 1: END_TOKEN, 2:PAD_TOKEN},\n        \"source_len\": 3,\n        \"target_len\": 3,\n        \"source_data\": source_data,\n        \"target_data\": target_data,\n        \"source_data_seq\": [],\n        \"target_data_seq\": []\n    }\n    \n    data[\"INPUT_MAX_LENGTH\"] = max(len(string) for string in source_data) +2\n    data[\"OUTPUT_MAX_LENGTH\"] = max(len(string) for string in target_data)+2\n\n    \n    padded_source_strings=add_padding(source_data, data[\"INPUT_MAX_LENGTH\"])\n    padded_target_strings = add_padding(target_data, data[\"OUTPUT_MAX_LENGTH\"])\n    \n    for i in range(len(padded_source_strings)):\n        for c in padded_source_strings[i]:\n            if data[\"source_char_index\"].get(c) is None:\n                data[\"source_chars\"].append(c)\n                idx = len(data[\"source_chars\"]) - 1\n                data[\"source_char_index\"][c] = idx\n                data[\"source_index_char\"][idx] = c\n        for c in padded_target_strings[i]:\n            if data[\"target_char_index\"].get(c) is None:\n                data[\"target_chars\"].append(c)\n                idx = len(data[\"target_chars\"]) - 1\n                data[\"target_char_index\"][c] = idx\n                data[\"target_index_char\"][idx] = c\n\n    data['source_data_seq'] = generate_string_to_sequence(padded_source_strings,  data['source_char_index'])\n    data['target_data_seq'] = generate_string_to_sequence(padded_target_strings,  data['target_char_index'])\n    print(data[\"source_data\"][0])\n    print(data[\"source_data_seq\"][0])\n    print(data[\"target_data\"][0])\n    print(data[\"target_data_seq\"][0])\n\n    \n    data[\"source_len\"] = len(data[\"source_chars\"])\n    data[\"target_len\"] = len(data[\"target_chars\"])\n    \n    return data\n\n\ndata = preprocess_data(copy.copy(train_source), copy.copy(train_target[:]))\nprint(data[\"source_chars\"])\nprint(data[\"target_chars\"])\nprint(data[\"source_len\"])\nprint(data[\"target_len\"])\nprint(data[\"INPUT_MAX_LENGTH\"])\nprint(data[\"OUTPUT_MAX_LENGTH\"])\n\n","metadata":{"_uuid":"0c3f2154-423f-4ef0-a4a1-c7c1423e2050","_cell_guid":"65d72dbd-08c1-417f-8101-7e4aa924a6b7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:22.365189Z","iopub.execute_input":"2024-05-04T10:00:22.365463Z","iopub.status.idle":"2024-05-04T10:00:30.287175Z","shell.execute_reply.started":"2024-05-04T10:00:22.36544Z","shell.execute_reply":"2024-05-04T10:00:30.286093Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"shastragaar\ntensor([0, 3, 4, 5, 3, 6, 7, 5, 8, 5, 5, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2], device='cuda:0')\nशस्त्रागार\ntensor([0, 3, 4, 5, 6, 5, 7, 8, 9, 8, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n       device='cuda:0')\n['<', '>', '_', 's', 'h', 'a', 't', 'r', 'g', 'b', 'i', 'n', 'd', 'y', 'k', 'o', 'p', 'v', 'e', 'c', 'm', 'u', 'w', 'l', 'j', 'x', 'f', 'z', 'q']\n['<', '>', '_', 'श', 'स', '्', 'त', 'र', 'ा', 'ग', 'ब', 'ि', 'न', 'द', 'य', 'क', 'ण', 'ं', 'ज', 'ञ', 'ो', 'प', 'व', 'ी', 'ट', 'च', 'े', 'भ', 'म', 'ध', 'ु', 'घ', 'ड', '़', 'ह', 'ल', 'ै', 'इ', 'ॉ', 'ू', 'अ', 'ए', 'ौ', 'आ', 'ई', 'झ', 'ः', 'ख', 'ष', 'उ', 'थ', 'छ', 'ठ', 'ँ', 'ओ', 'फ', 'ढ', 'ऊ', 'ृ', 'ऐ', 'ळ', 'ऋ', 'औ', 'ऑ', 'ॅ', 'ङ', 'ऽ']\n29\n67\n22\n26\n","output_type":"stream"}]},{"cell_type":"code","source":"h_params={\n    \"char_embd_dim\" : 256, \n    \"hidden_layer_neurons\":512,\n    \"batch_size\":64,\n    \"number_of_layers\":3,\n    \"learning_rate\":0.001,\n    \"epochs\":30,\n    \"cell_type\":\"LSTM\",\n    \"dropout\":0,\n    \"optimizer\":\"adam\"\n}","metadata":{"_uuid":"09e23475-cfc0-4391-84d4-e2ed63bf810d","_cell_guid":"29792c2b-f3aa-41d7-a659-100e89b4db16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-04T10:00:30.289111Z","iopub.execute_input":"2024-05-04T10:00:30.289474Z","iopub.status.idle":"2024-05-04T10:00:30.295497Z","shell.execute_reply.started":"2024-05-04T10:00:30.289444Z","shell.execute_reply":"2024-05-04T10:00:30.294467Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def get_cell_type(cell_type):\n    if(cell_type == \"RNN\"):\n        return nn.RNN\n    elif(cell_type == \"LSTM\"):\n        return nn.LSTM\n    elif(cell_type == \"GRU\"):\n        return nn.GRU\n    else:\n        print(\"Specify correct cell type\")\n        \nclass Encoder(nn.Module):\n    def __init__(self, h_params, data, device ):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(data[\"source_len\"], h_params[\"char_embd_dim\"])\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],num_layers=h_params[\"number_of_layers\"], dropout= h_params[\"dropout\"],batch_first=True)\n        self.device=device\n        self.h_params = h_params\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        embd_input = self.dropout(embd_input)\n        output, prev_state = self.cell(embd_input, prev_state)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(h_params[\"number_of_layers\"],h_params[\"batch_size\"],h_params[\"hidden_layer_neurons\"], device=self.device)\n\n    \nclass Decoder(nn.Module):\n    def __init__(self, h_params, data,device):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(data[\"target_len\"], h_params[\"char_embd_dim\"])\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],num_layers=h_params[\"number_of_layers\"],dropout= h_params[\"dropout\"], batch_first=True)\n        self.fc = nn.Linear(h_params[\"hidden_layer_neurons\"], data[\"target_len\"])\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        curr_embd = self.dropout(curr_embd)\n        output, prev_state = self.cell(curr_embd, prev_state)\n        output = self.softmax(self.fc(output))\n        return output, prev_state","metadata":{"_uuid":"d6ff26fc-b5de-4249-88b2-ea263b8b37c8","_cell_guid":"64c71a02-dc40-465e-8aef-83951c8347f6","execution":{"iopub.status.busy":"2024-05-04T10:00:30.296899Z","iopub.execute_input":"2024-05-04T10:00:30.297218Z","iopub.status.idle":"2024-05-04T10:00:30.315198Z","shell.execute_reply.started":"2024-05-04T10:00:30.297192Z","shell.execute_reply":"2024-05-04T10:00:30.314113Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data):\n        self.source_data_seq = data[0]\n        self.target_data_seq = data[1]\n    \n    def __len__(self):\n        return len(self.source_data_seq)\n    \n    def __getitem__(self, idx):\n        source_data = self.source_data_seq[idx]\n        target_data = self.target_data_seq[idx]\n        return source_data, target_data","metadata":{"_uuid":"eef0859f-56b6-4d6d-b89b-9bed47039138","_cell_guid":"48023388-f9f6-43b9-9875-6957e3394472","execution":{"iopub.status.busy":"2024-05-04T10:00:30.317751Z","iopub.execute_input":"2024-05-04T10:00:30.318054Z","iopub.status.idle":"2024-05-04T10:00:30.328733Z","shell.execute_reply.started":"2024-05-04T10:00:30.318027Z","shell.execute_reply":"2024-05-04T10:00:30.327733Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"val_padded_source_strings=add_padding(val_source, data[\"INPUT_MAX_LENGTH\"])\nval_padded_target_strings = add_padding(val_target, data[\"OUTPUT_MAX_LENGTH\"])\nval_source_sequences = generate_string_to_sequence(val_padded_source_strings,  data['source_char_index'])\nval_target_sequences = generate_string_to_sequence(val_padded_target_strings,  data['target_char_index'])\nvalidation_data = [val_source_sequences, val_target_sequences]\nval_dataset = MyDataset(validation_data)\nval_dataloader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T10:00:30.329936Z","iopub.execute_input":"2024-05-04T10:00:30.330276Z","iopub.status.idle":"2024-05-04T10:00:30.952388Z","shell.execute_reply.started":"2024-05-04T10:00:30.330245Z","shell.execute_reply":"2024-05-04T10:00:30.951354Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def inference(encoder, decoder, source_sequence, target_tensor, data, device, h_params, loss_fn, batch_num):\n    encoder.eval()\n    decoder.eval()\n    \n    loss = 0\n    correct = 0\n    with torch.no_grad():\n        encoder_hidden = encoder.getInitialState()\n#         print(source_sequence.shape)\n#         print(source_sequence)\n        if h_params[\"cell_type\"] == \"LSTM\":\n            encoder_hidden = (encoder_hidden, encoder.getInitialState())\n        encoder_outputs, encoder_hidden = encoder(source_sequence, encoder_hidden)\n#         print(encoder_hidden.shape)\n#         print(encoder_hidden)\n\n        decoder_input = torch.full((h_params[\"batch_size\"], 1), data['target_char_index'][START_TOKEN], device=device)  # Start token\n#         print(decoder_input)\n        decoder_actual_output = []\n        \n        decoder_hidden = encoder_hidden\n        for di in range(data[\"OUTPUT_MAX_LENGTH\"]):\n            curr_target_chars = target_tensor[:, di]\n            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input_tensor = topi.squeeze().detach()\n#             print(decoder_input_tensor.shape)\n#             print(decoder_input_tensor)\n            decoder_actual_output.append(decoder_input_tensor)\n            decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                        \n            decoder_output = decoder_output[:, -1, :]\n            loss+=(loss_fn(decoder_output, curr_target_chars))\n\n        decoder_actual_output = torch.cat(decoder_actual_output,dim=0).view(data[\"OUTPUT_MAX_LENGTH\"], h_params[\"batch_size\"]).transpose(0,1)\n        if(batch_num %100== 0):\n                print(\"<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\n\")\n                for j in range(20):\n                    print(\"batch num: \", batch_num, \"val_acc\", make_strings(data,source_sequence[j],target_tensor[j],decoder_actual_output[j]))\n\n        correct = (decoder_actual_output == target_tensor).all(dim=1).sum().item()\n#         if(batch_num%20 == 0):\n#             print(\"ep:\", ep, \" bt:\", batch_num, \" loss:\", loss.item()/output_seq_len, \" acc: \", correct/h_params[\"batch_size\"])\n        return correct, loss.item()/data[\"OUTPUT_MAX_LENGTH\"]\n    \n    \ndef evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn):\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    print(number_of_batches)\n    print(total_predictions)\n    for batch_num, (source_sequence, target_sequence) in enumerate(dataloader):\n        input_tensor = source_sequence\n        target_tensor = target_sequence\n        \n        correct, loss = inference(encoder, decoder, input_tensor, target_tensor, data, device, h_params, loss_fn, batch_num)\n        \n        correct_predictions+=correct\n        total_loss +=loss\n    \n    accuracy = correct_predictions / total_predictions\n    total_loss /= number_of_batches\n    \n    print(\"accuracy: \", accuracy, \" loss:\", total_loss)\n    return accuracy, total_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T10:00:30.95381Z","iopub.execute_input":"2024-05-04T10:00:30.954854Z","iopub.status.idle":"2024-05-04T10:00:30.970024Z","shell.execute_reply.started":"2024-05-04T10:00:30.954819Z","shell.execute_reply":"2024-05-04T10:00:30.969068Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def make_strings(data, source, target, output):\n    source_string = \"\"\n    target_string = \"\"\n    output_string = \"\"\n#     print(output)\n    for i in source:\n#         print(i.item())\n        source_string+=(data['source_index_char'][i.item()])\n    for i in target:\n        target_string+=(data['target_index_char'][i.item()])\n    for i in output:\n        output_string+=(data['target_index_char'][i.item()])\n    return source_string, target_string, output_string\n\n\n\ndef train_loop(encoder, decoder,h_params, data, data_loader, device):\n    if h_params[\"optimizer\"] == \"adam\":\n        encoder_optimizer = optim.Adam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.Adam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    elif h_params[\"optimizer\"] == \"nadam\":\n        encoder_optimizer = optim.NAdam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.NAdam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    \n    total_predictions = len(data_loader.dataset)\n    total_batches = len(data_loader)\n    loss_fn = nn.NLLLoss()\n    for ep in range(h_params[\"epochs\"]):\n        encoder.train()\n        decoder.train()\n        total_loss = 0\n        total_correct = 0\n        for batch_num, (source_batch, target_batch) in enumerate(data_loader):\n#             if(batch_num>0):\n#                 break\n            encoder_initial_state = encoder.getInitialState()\n            if h_params[\"cell_type\"] == \"LSTM\":\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n            \n            encoder_current_state = encoder_initial_state\n            encoder_output, encoder_current_state = encoder(source_batch,encoder_current_state)\n            loss = 0\n            correct = 0\n            decoder_curr_state = encoder_current_state\n            output_seq_len = data[\"OUTPUT_MAX_LENGTH\"]\n            decoder_actual_output = []\n            \n            use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n\n            for i in range(data[\"OUTPUT_MAX_LENGTH\"]):\n                if(i == 0):\n                    dec_input_tensor = target_batch[:, i].view(h_params[\"batch_size\"],1)\n                curr_target_chars = target_batch[:, i]\n                decoder_output, decoder_curr_state = decoder(dec_input_tensor,decoder_curr_state)\n                topv, topi = decoder_output.topk(1)\n                decoder_input_tensor = topi.squeeze().detach()\n                decoder_actual_output.append(decoder_input_tensor)\n                if(i<output_seq_len-1):\n                    if use_teacher_forcing:\n                        decoder_input_tensor = target_batch[:, i+1].view(h_params[\"batch_size\"], 1)\n                    else:\n                        decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                decoder_output = decoder_output[:, -1, :]\n                loss+=(loss_fn(decoder_output, curr_target_chars))\n\n            decoder_actual_output = torch.cat(decoder_actual_output,dim=0).view(output_seq_len, h_params[\"batch_size\"]).transpose(0,1)\n            if(batch_num == 0):\n                    for j in range(20):\n                        print(make_strings(data,source_batch[j],target_batch[j],decoder_actual_output[j]))\n            \n            correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            total_correct+=correct;\n            total_loss += loss.item()/output_seq_len;\n            if(batch_num%50 == 0):\n                print(\"ep:\", ep, \" bt:\", batch_num, \" loss:\", loss.item()/output_seq_len, \" acc: \", correct/h_params[\"batch_size\"])\n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            loss.backward()\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n        \n        print(\"ep: \", ep, \" train acc:\", total_correct/total_predictions, \" loss:\", total_loss/total_batches)\n        evaluate(encoder, decoder, data, val_dataloader,device, h_params, loss_fn)\n#     encoder=None\n#     decoder=None\n#     gc.collect()\n#     torch.cuda.empty_cache() \n    return encoder, decoder, loss_fn","metadata":{"_uuid":"f704842a-033b-40ea-af52-bccdea8a5014","_cell_guid":"b704c17c-662e-49d1-93df-5eefeadf24a5","scrolled":true,"execution":{"iopub.status.busy":"2024-05-04T10:00:30.971332Z","iopub.execute_input":"2024-05-04T10:00:30.971697Z","iopub.status.idle":"2024-05-04T10:00:30.995455Z","shell.execute_reply.started":"2024-05-04T10:00:30.971649Z","shell.execute_reply":"2024-05-04T10:00:30.99438Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"training_data = [data[\"source_data_seq\"], data['target_data_seq']]\nmy_dataset = MyDataset(training_data)\ndata_loader = DataLoader(my_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\ndef train(h_params, data, device, data_loader):\n    encoder = Encoder(h_params, data, device).to(device)\n    decoder = Decoder(h_params, data, device).to(device)\n    \n    encoder,  decoder, loss_fn = train_loop(encoder, decoder,h_params, data, data_loader,device)\n    return encoder, decoder, loss_fn\n\nencoder, decoder, loss_fn = train(h_params, data, device, data_loader)\n","metadata":{"_uuid":"57e95586-3f42-4dad-aed7-0bb263f699df","_cell_guid":"85d681a3-36e8-43ad-829f-2a14fb95a810","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-04T10:00:30.996676Z","iopub.execute_input":"2024-05-04T10:00:30.996999Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"('<auratamaam>______________', '<औरतमाम>______________', 'ञाससणााााााााााााााााा')\n('<otgun>___________________', '<ओटगन>________________', 'ञाससणााााााााााााााााा')\n('<krishnamurari>___________', '<कृष्णमुरारी>_________', 'ञाससणााााााााााााााााा')\n('<dhyanbal>________________', '<ध्यानबल>_____________', 'ञाससणााााााााााााााााा')\n('<tikarthiyon>_____________', '<टिकार्थियों>_________', 'ञाससणााााााााााााााााा')\n('<rangilpura>______________', '<रंगीलपुरा>___________', 'ञाससणााााााााााााााााा')\n('<chupchupa>_______________', '<चुपचुपा>_____________', 'ञाससणााााााााााााााााा')\n('<scalaper>________________', '<स्केलेपर>____________', 'ञाससणााााााााााााााााा')\n('<singhohi>________________', '<सिंघोही>_____________', 'ञाससणााााााााााााााााा')\n('<duhariya>________________', '<दुहरिया>_____________', 'ञाससणााााााााााााााााा')\n('<ranimandi>_______________', '<रानीमंडी>____________', 'ञाससणााााााााााााााााा')\n('<quwatul>_________________', '<कुबातुल>_____________', 'ञाससणााााााााााााााााा')\n('<rekhavose>_______________', '<रेखावोसे>____________', 'ञाससणााााााााााााााााा')\n('<padrtiyon>_______________', '<पद्रतियो>____________', 'ञाससणााााााााााााााााा')\n('<javarimal>_______________', '<जवरीमल>______________', 'ञाससणााााााााााााााााा')\n('<minitacha>_______________', '<मिनीटाचा>____________', 'ञाससणााााााााााााााााा')\n('<eucalyptis>______________', '<यूकेलिप्टिस>_________', 'ञाससणााााााााााााााााा')\n('<imarte>__________________', '<इमार्ते>_____________', 'ञाससणााााााााााााााााा')\n('<mirchichya>______________', '<मिरचीच्या>___________', 'ञाससणााााााााााााााााा')\n('<arejina>_________________', '<अरेजिना>_____________', 'ञाससणााााााााााााााााा')\nep: 0  bt: 0  loss: 4.1992731961337  acc:  0.0\nep: 0  bt: 50  loss: 1.4625134901566939  acc:  0.0\nep: 0  bt: 100  loss: 1.3322484276511453  acc:  0.0\nep: 0  bt: 150  loss: 1.3733895041725852  acc:  0.0\nep: 0  bt: 200  loss: 1.2560741251165217  acc:  0.0\nep: 0  bt: 250  loss: 1.25591702894731  acc:  0.0\nep: 0  bt: 300  loss: 1.2876477675004439  acc:  0.0\nep: 0  bt: 350  loss: 1.3712825775146484  acc:  0.0\nep: 0  bt: 400  loss: 1.2706327438354492  acc:  0.0\nep: 0  bt: 450  loss: 1.1295610774647107  acc:  0.0\nep: 0  bt: 500  loss: 1.1485640785910867  acc:  0.0\nep: 0  bt: 550  loss: 1.0222706361250444  acc:  0.0\nep: 0  bt: 600  loss: 1.0790387933904475  acc:  0.0\nep: 0  bt: 650  loss: 1.0105890794233843  acc:  0.0\nep: 0  bt: 700  loss: 1.0310380242087624  acc:  0.0\nep: 0  bt: 750  loss: 0.8410579508001154  acc:  0.0\nep:  0  train acc: 0.0001953125  loss: 1.2122133627804852\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<jeevanheen>______________', '<जीवनहीन>_____________', '<जेवाााे>>____________')\nbatch num:  0 val_acc ('<fort>____________________', '<फॉर्ट>_______________', '<फोरोट>_______________')\nbatch num:  0 val_acc ('<sriperu>_________________', '<श्रीपेरू>____________', '<स्र्रोर>>____________')\nbatch num:  0 val_acc ('<hunar>___________________', '<हुनर>________________', '<हुनरर>_______________')\nbatch num:  0 val_acc ('<lagakar>_________________', '<लगाकर>_______________', '<लाारर>_______________')\nbatch num:  0 val_acc ('<leti>____________________', '<लेती>________________', '<लिटी>>_______________')\nbatch num:  0 val_acc ('<dhumra>__________________', '<धूम्र>_______________', '<धुनार>_______________')\nbatch num:  0 val_acc ('<downloding>______________', '<डाउनलोडिंग>__________', '<दोनोललललं>>__________')\nbatch num:  0 val_acc ('<raghawanand>_____________', '<राघवानंद>____________', '<राहाााी>>____________')\nbatch num:  0 val_acc ('<dohru>___________________', '<दोहरू>_______________', '<दोहुर>_______________')\nbatch num:  0 val_acc ('<uddeshyparak>____________', '<उद्देश्यपरक>_________', '<अद्दिस्््र>>_________')\nbatch num:  0 val_acc ('<balat>___________________', '<बलात>________________', '<बाजत>________________')\nbatch num:  0 val_acc ('<loharanpurwa>____________', '<लोहारनपुरवा>_________', '<लोहररुरररा>__________')\nbatch num:  0 val_acc ('<bullion>_________________', '<बुलियन>______________', '<बुलललो>>_____________')\nbatch num:  0 val_acc ('<ishwarla>________________', '<ईश्वरला>_____________', '<अश्वााल>>____________')\nbatch num:  0 val_acc ('<aadat>___________________', '<आदत>_________________', '<अहात>________________')\nbatch num:  0 val_acc ('<aauu>____________________', '<आऊ>__________________', '<आनू>>________________')\nbatch num:  0 val_acc ('<newyorp>_________________', '<न्यूयार्प>___________', '<निवाुपर>>____________')\nbatch num:  0 val_acc ('<failaayen>_______________', '<फैलाएं>______________', '<फैललला>>_____________')\nbatch num:  0 val_acc ('<basis>___________________', '<बेसिस>_______________', '<बैसिस>>______________')\naccuracy:  0.0087890625  loss: 0.7201533486897295\n('<wordfare>________________', '<वर्डफेयर>____________', '<वोरोलेरे>>___________')\n('<jasmahinder>_____________', '<जसमहिंद्र>___________', '<जससमााा्त>>__________')\n('<birambad>________________', '<बिरम्बद>_____________', '<ब्रागदद>>____________')\n('<pitrichatra>_____________', '<पितृछत्र>____________', '<पिट्त्त्रा>__________')\n('<machaat>_________________', '<मचात>________________', '<माात>>_______________')\n('<procurement>_____________', '<प्रोक्यूर्मेंट>______', '<प्रोटोोोट्ट>_________')\n('<pahaletak>_______________', '<पहलेतक>______________', '<पााेेे>>_____________')\n('<shtavishaya>_____________', '<ष्टविषय>_____________', '<श्राववााा>___________')\n('<nippless>________________', '<निप्पलेस>____________', '<निट्ोोल्स>___________')\n('<shramsudhar>_____________', '<श्रमसुधार>___________', '<श्राुााा>>___________')\n('<dhunna>__________________', '<धुन्ना>______________', '<धुनाा>_______________')\n('<cheepen>_________________', '<चीपें>_______________', '<चेकेो>>______________')\n('<aandhiyan>_______________', '<आंधियाँ>_____________', '<अनुववाा>>____________')\n('<paritaktya>______________', '<परितक्त्या>__________', '<पररतततततयय>__________')\n('<kibai>___________________', '<किबाई>_______________', '<किला>>_______________')\n('<navpashanyug>____________', '<नवपाषाणयुग>__________', '<ना््पुुुो>>__________')\n('<nitrosomonas>____________', '<नाइट्रोसोमोनास>______', '<निट्रोोोोोस>_________')\n('<daadaaon>________________', '<दादाओं>______________', '<दाााों>______________')\n('<mungati>_________________', '<मुंगाती>_____________', '<मुंगिी>>_____________')\n('<samardha>________________', '<समर्धा>______________', '<समााााा>_____________')\nep: 1  bt: 0  loss: 0.8726106990467418  acc:  0.0\nep: 1  bt: 50  loss: 0.8939568779685281  acc:  0.03125\nep: 1  bt: 100  loss: 0.7369398637251421  acc:  0.015625\nep: 1  bt: 150  loss: 0.7790776166048917  acc:  0.0\nep: 1  bt: 200  loss: 0.7238795107061212  acc:  0.015625\nep: 1  bt: 250  loss: 0.7514983090487394  acc:  0.03125\nep: 1  bt: 300  loss: 0.781996033408425  acc:  0.015625\nep: 1  bt: 350  loss: 0.7712858373468573  acc:  0.03125\nep: 1  bt: 400  loss: 0.5491334308277477  acc:  0.046875\nep: 1  bt: 450  loss: 0.6720973795110529  acc:  0.03125\nep: 1  bt: 500  loss: 0.6402456110174005  acc:  0.03125\nep: 1  bt: 550  loss: 0.5568123730746183  acc:  0.0625\nep: 1  bt: 600  loss: 0.641109206459739  acc:  0.03125\nep: 1  bt: 650  loss: 0.504071669145064  acc:  0.09375\nep: 1  bt: 700  loss: 0.624775539744984  acc:  0.078125\nep:  1  train acc: 0.04017578125  loss: 0.6645842746171087\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<yatim>___________________', '<यतीम>________________', '<यतिम>>_______________')\nbatch num:  0 val_acc ('<urvarak>_________________', '<उर्वरक>______________', '<उू्वरकक______________')\nbatch num:  0 val_acc ('<arc>_____________________', '<एआरसी>_______________', '<एररएीएी______________')\nbatch num:  0 val_acc ('<bhar>____________________', '<भार>_________________', '<भार>_________________')\nbatch num:  0 val_acc ('<chandsarai>______________', '<चंदसराय>_____________', '<चंददारा>>____________')\nbatch num:  0 val_acc ('<arendi>__________________', '<अरंडी>_______________', '<अरेंदी>______________')\nbatch num:  0 val_acc ('<rishabh>_________________', '<रिषभ>________________', '<रिशा>>_______________')\nbatch num:  0 val_acc ('<dabok>___________________', '<डबोक>________________', '<डबोक>>_______________')\nbatch num:  0 val_acc ('<asar>____________________', '<असर>_________________', '<असा>>________________')\nbatch num:  0 val_acc ('<pushpiya>________________', '<पुष्पीय>_____________', '<पुश्पिया>____________')\nbatch num:  0 val_acc ('<tamizah>_________________', '<तमीज़ाह>_____________', '<तममिाा>______________')\nbatch num:  0 val_acc ('<pachchajanya>____________', '<पाञ्चजन्य>___________', '<पच्चां्यय>___________')\nbatch num:  0 val_acc ('<shakni>__________________', '<शकनी>________________', '<शक्न>________________')\nbatch num:  0 val_acc ('<premanand>_______________', '<प्रेमानंद>___________', '<प्रेमनंदद>___________')\nbatch num:  0 val_acc ('<shasakiy>________________', '<शासकीय>______________', '<शा्िी>_______________')\nbatch num:  0 val_acc ('<ddt>_____________________', '<डीडीटी>______________', '<डीडीटी>______________')\nbatch num:  0 val_acc ('<najraana>________________', '<नज़राना>_____________', '<नजरााा>______________')\nbatch num:  0 val_acc ('<gagapul>_________________', '<गगापुल>______________', '<गगापुल>______________')\nbatch num:  0 val_acc ('<chhalaik>________________', '<छलैक>________________', '<छललक>________________')\nbatch num:  0 val_acc ('<kurkura>_________________', '<कुरकुरा>_____________', '<कुरककुर>_____________')\naccuracy:  0.125244140625  loss: 0.4335379454899918\n('<loropyriphos>____________', '<लोरोपायरीफॉस>________', '<लोरोपियोस्स>_________')\n('<backstory>_______________', '<बैकस्टोरी>___________', '<बैक्सटटरी>___________')\n('<rattangarh>______________', '<रत्तनगढ़>____________', '<रत्तागग>>____________')\n('<kararasathi>_____________', '<करारासाठी>___________', '<करराााठी>____________')\n('<chitrafalakon>___________', '<चित्रफलकों>__________', '<चित्राललकों>_________')\n('<sitaramsharan>___________', '<सीतारामशरण>__________', '<सितररमा्ण>___________')\n('<jogipada>________________', '<जोगीपाड़ा>___________', '<जोगीपााा_____________')\n('<ajnila>__________________', '<अजनीला>______________', '<अज्नला>______________')\n('<melchior>________________', '<मेलकिओर>_____________', '<मेलचिि>>_____________')\n('<kuntinandan>_____________', '<कुन्तीनन्दन>_________', '<कुंतिनंंननन__________')\n('<saskatoon>_______________', '<सास्काटून>___________', '<सस्तुुन>_____________')\n('<jarpi>___________________', '<जारपी>_______________', '<जरपीी>_______________')\n('<upadal>__________________', '<उपदल>________________', '<उपााल>_______________')\n('<palaamuun>_______________', '<पलामूँ>______________', '<पलामूू>______________')\n('<bughar>__________________', '<बुघार>_______________', '<बुघार>_______________')\n('<pakirisamy>______________', '<पकिरिसामी>___________', '<पकिरिसमम>>___________')\n('<chhahura>________________', '<छहुरा>_______________', '<छाुरा>_______________')\n('<dekhtedekhte>____________', '<देखतेदेखते>__________', '<देखतेदेेेत>__________')\n('<atindreeya>______________', '<अतीन्द्रिय>__________', '<अतिं्र््य>___________')\n('<paryataksthal>___________', '<पर्यटकस्थल>__________', '<पर्यत्क्षाल>_________')\nep: 2  bt: 0  loss: 0.5561185316606001  acc:  0.078125\nep: 2  bt: 50  loss: 0.6854619112881747  acc:  0.046875\nep: 2  bt: 100  loss: 0.5634078979492188  acc:  0.015625\nep: 2  bt: 150  loss: 0.5544312217018821  acc:  0.046875\nep: 2  bt: 200  loss: 0.5163919275457208  acc:  0.15625\nep: 2  bt: 250  loss: 0.5600081357088956  acc:  0.046875\nep: 2  bt: 300  loss: 0.5664165236733176  acc:  0.046875\nep: 2  bt: 350  loss: 0.5392349850047718  acc:  0.046875\nep: 2  bt: 400  loss: 0.5014303814281117  acc:  0.109375\nep: 2  bt: 450  loss: 0.522539268840443  acc:  0.125\nep: 2  bt: 500  loss: 0.5467655875466086  acc:  0.125\nep: 2  bt: 550  loss: 0.494826230135831  acc:  0.109375\nep: 2  bt: 600  loss: 0.4694642153653232  acc:  0.125\nep: 2  bt: 650  loss: 0.4185449860312722  acc:  0.15625\nep: 2  bt: 700  loss: 0.4316007007252086  acc:  0.0625\nep: 2  bt: 750  loss: 0.5796675682067871  acc:  0.046875\nep:  2  train acc: 0.10005859375  loss: 0.5025352608344771\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<earthing>________________', '<अर्थिंग>_____________', '<एर्थिंग>_____________')\nbatch num:  0 val_acc ('<angithi>_________________', '<अंगीठी>______________', '<अंगिती>______________')\nbatch num:  0 val_acc ('<harda>___________________', '<हरदा>________________', '<हरराा>_______________')\nbatch num:  0 val_acc ('<kutub>___________________', '<कुतुब>_______________', '<कुटुब>_______________')\nbatch num:  0 val_acc ('<sunaayenge>______________', '<सुनाएँगे>____________', '<सुनाएंगे>____________')\nbatch num:  0 val_acc ('<navaasiyon>______________', '<नवासियों>____________', '<नवासियों>____________')\nbatch num:  0 val_acc ('<scotiabank>______________', '<स्कॉटियाबैंक>________', '<स्कोटियानक>>_________')\nbatch num:  0 val_acc ('<canedi>__________________', '<कैनेडी>______________', '<कैनेडी>______________')\nbatch num:  0 val_acc ('<majan>___________________', '<मजन>_________________', '<मजनन>________________')\nbatch num:  0 val_acc ('<spotify>_________________', '<स्पॉटिफाई>___________', '<स्पोफिफि>____________')\nbatch num:  0 val_acc ('<bitaayaa>________________', '<बिताया>______________', '<बिताया>______________')\nbatch num:  0 val_acc ('<madhurimarajehi>_________', '<मधुरिमाराजेही>_______', '<मधुरिरीराााी>________')\nbatch num:  0 val_acc ('<pradhyapak>______________', '<प्राध्यापक>__________', '<प्रध्यापप>>__________')\nbatch num:  0 val_acc ('<approver>________________', '<अप्रूवर>_____________', '<एप्रोववर>____________')\nbatch num:  0 val_acc ('<specifications>__________', '<स्पैसिफिकेशन्स>______', '<स्पेसिफिकिक्न>>______')\nbatch num:  0 val_acc ('<bhagate>_________________', '<भागते>_______________', '<भगतेे>_______________')\nbatch num:  0 val_acc ('<sabhyataon>______________', '<सभ्यताओं>____________', '<सभ्यताओं>____________')\nbatch num:  0 val_acc ('<sunhaira>________________', '<सुन्हैरा>____________', '<सुनहहिरा>____________')\nbatch num:  0 val_acc ('<sailfiyaan>______________', '<सैल्फियां>___________', '<सैल्िियाँ>___________')\nbatch num:  0 val_acc ('<borkheda>________________', '<बोरखेड़ा>____________', '<बोरखेड़ा>____________')\naccuracy:  0.14892578125  loss: 0.39588134126229724\n('<pasaaiye>________________', '<पसाइये>______________', '<पसायय>>______________')\n('<glasshouse>______________', '<ग्लासहाउस>___________', '<ग्लासोश>>____________')\n('<pravrajika>______________', '<प्रव्राजिका>_________', '<प्रवररजिका>__________')\n('<jinkaychech>_____________', '<जिंकायचेच>___________', '<जिनकााचचे>___________')\n('<mahokh>__________________', '<महोख>________________', '<महोख>________________')\n('<batchmats>_______________', '<बैचमैट्स>____________', '<बैचमम््स>____________')\n('<satawa>__________________', '<सतावा>_______________', '<सतावा>_______________')\n('<samajhalaki>_____________', '<समझलकी>______________', '<सझझलकी>______________')\n('<hiriye>__________________', '<हिरिए>_______________', '<हिरिये>______________')\n('<implementation>__________', '<इम्पलिमेंटेशन>_______', '<इम्पलेेेेेेशश>_______')\n('<blaydes>_________________', '<ब्लेड्स>_____________', '<ब्लाडडडस>____________')\n('<paanchavaa>______________', '<पांचवां>_____________', '<पांवाा>______________')\n('<paryogvaadi>_____________', '<प्रयोगवादी>__________', '<पररयोगवडडीी>_________')\n('<anantanarayanan>_________', '<अनंतनारायनन>_________', '<अनतततरररणणण>_________')\n('<warisa>__________________', '<वारिसा>______________', '<वारससा>______________')\n('<jaminmalkachi>___________', '<जमीनमालकाची>_________', '<जमिमममलााची>_________')\n('<paint>___________________', '<पैन्ट>_______________', '<पैंट>________________')\n('<jaapaaniyon>_____________', '<जापानियों>___________', '<जापािियों>___________')\n('<pijaur>__________________', '<पिजौर>_______________', '<पिजौर>_______________')\n('<khashm>__________________', '<खश्म>________________', '<खश्म>________________')\nep: 3  bt: 0  loss: 0.41175824945623224  acc:  0.1875\nep: 3  bt: 50  loss: 0.38023116371848364  acc:  0.15625\nep: 3  bt: 100  loss: 0.47969874468716706  acc:  0.125\nep: 3  bt: 150  loss: 0.39427614212036133  acc:  0.078125\nep: 3  bt: 200  loss: 0.42756297371604224  acc:  0.15625\nep: 3  bt: 250  loss: 0.4012810100208629  acc:  0.203125\nep: 3  bt: 300  loss: 0.47754188017411664  acc:  0.109375\nep: 3  bt: 350  loss: 0.4100744074041193  acc:  0.109375\nep: 3  bt: 400  loss: 0.42584228515625  acc:  0.15625\nep: 3  bt: 450  loss: 0.4588667696172541  acc:  0.09375\nep: 3  bt: 500  loss: 0.5116439732638273  acc:  0.125\nep: 3  bt: 550  loss: 0.38516374067826703  acc:  0.140625\nep: 3  bt: 600  loss: 0.36930287968028674  acc:  0.171875\nep: 3  bt: 650  loss: 0.4717033559625799  acc:  0.078125\nep: 3  bt: 700  loss: 0.5135025978088379  acc:  0.15625\nep: 3  bt: 750  loss: 0.4583739800886674  acc:  0.109375\nep:  3  train acc: 0.1427734375  loss: 0.43617755583741447\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<bhulate>_________________', '<भूलते>_______________', '<भुलते>_______________')\nbatch num:  0 val_acc ('<jamval>__________________', '<जामवाल>______________', '<जमवल>________________')\nbatch num:  0 val_acc ('<mutashabih>______________', '<मताशबीह>_____________', '<मुताशभभी>____________')\nbatch num:  0 val_acc ('<nangligodha>_____________', '<नंगलीगोधा>___________', '<नंंगिगोोढा>__________')\nbatch num:  0 val_acc ('<chhaayaaprati>___________', '<छायाप्रति>___________', '<छायापर्ति>___________')\nbatch num:  0 val_acc ('<kanhachak>_______________', '<कान्हाचक>____________', '<कन्हाच>______________')\nbatch num:  0 val_acc ('<jhar>____________________', '<झर>__________________', '<झर>>_________________')\nbatch num:  0 val_acc ('<statioran>_______________', '<स्टेशरन>_____________', '<स्टैशियर>____________')\nbatch num:  0 val_acc ('<aushdhalay>______________', '<औषधालय>______________', '<औषधलयय>______________')\nbatch num:  0 val_acc ('<iqbal>___________________', '<इकबाल>_______________', '<इकसबा>_______________')\nbatch num:  0 val_acc ('<ionize>__________________', '<आयोनाइज>_____________', '<आईओििइ>>_____________')\nbatch num:  0 val_acc ('<boel>____________________', '<बोएल>________________', '<बोईल_________________')\nbatch num:  0 val_acc ('<dimaagon>________________', '<दिमागों>_____________', '<दिमागगं>_____________')\nbatch num:  0 val_acc ('<faldayak>________________', '<फलदायक>______________', '<फल्दयक>______________')\nbatch num:  0 val_acc ('<oshikai>_________________', '<ओशिकाई>______________', '<ओशिका>_______________')\nbatch num:  0 val_acc ('<kyuubik>_________________', '<क्यूबिक>_____________', '<क्यूबििक>____________')\nbatch num:  0 val_acc ('<pratinidhitva>___________', '<प्रतिनिधित्व>________', '<प्रतिनिनित्व>________')\nbatch num:  0 val_acc ('<roberta>_________________', '<रोबर्टा>_____________', '<रोबर्टा>_____________')\nbatch num:  0 val_acc ('<janiye>__________________', '<जानिए>_______________', '<जनिय>>_______________')\nbatch num:  0 val_acc ('<hathak>__________________', '<हथक>_________________', '<हथक>_________________')\naccuracy:  0.1962890625  loss: 0.36829618669369\n('<ratnipur>________________', '<रतनीपुर>_____________', '<रतनिपुर>_____________')\n('<khinchwal>_______________', '<खींचवाल>_____________', '<खिंचवाल>_____________')\n('<khambatta>_______________', '<खम्बाट्टा>___________', '<खामबत्ा>_____________')\n('<chandrani>_______________', '<चन्द्रानी>___________', '<चंद््नन>_____________')\n('<dhamode>_________________', '<धामोडे>______________', '<धमोड़>_______________')\n('<tolein>__________________', '<तोलें>_______________', '<तोलेन>_______________')\n('<nighavet>________________', '<निघावेत>_____________', '<निघववे>______________')\n('<hajjar>__________________', '<हज्जर>_______________', '<हज्जर>_______________')\n('<gyaandhar>_______________', '<ज्ञानधर>_____________', '<ज्ञानधर>_____________')\n('<haldawari>_______________', '<हलदवारी>_____________', '<हलदवावी>_____________')\n('<paintshop>_______________', '<पेंटशॉप>_____________', '<पैंटटशपप_____________')\n('<mayanagari>______________', '<मायानगरी>____________', '<मायननगरी>____________')\n('<okayam>__________________', '<ओकायाम>______________', '<ओकायम>_______________')\n('<darakhton>_______________', '<दरख्तों>_____________', '<दररखतों>_____________')\n('<purtatebabat>____________', '<पूर्ततेबाबत>_________', '<पुर्ततेबबतत>_________')\n('<dastgeer>________________', '<दस्तगीर>_____________', '<दस्तगगर>_____________')\n('<nidashalaya>_____________', '<निदाशालय>____________', '<निदाशलयय>____________')\n('<chayanika>_______________', '<छायानिका>____________', '<चायनिका>_____________')\n('<varia>___________________', '<वारिया>______________', '<वारिया>______________')\n('<jhakjhod>________________', '<झकझोड>_______________', '<झकझोड>_______________')\nep: 4  bt: 0  loss: 0.3547310395674272  acc:  0.203125\nep: 4  bt: 50  loss: 0.3668391921303489  acc:  0.234375\nep: 4  bt: 100  loss: 0.3749188943342729  acc:  0.15625\nep: 4  bt: 150  loss: 0.34887016903270374  acc:  0.296875\nep: 4  bt: 200  loss: 0.42165084318681195  acc:  0.15625\nep: 4  bt: 250  loss: 0.34770412878556684  acc:  0.171875\nep: 4  bt: 300  loss: 0.33638711409135297  acc:  0.21875\nep: 4  bt: 350  loss: 0.45036922801624646  acc:  0.09375\nep: 4  bt: 400  loss: 0.42279850352894177  acc:  0.21875\nep: 4  bt: 450  loss: 0.4132297255776145  acc:  0.21875\nep: 4  bt: 500  loss: 0.31017977541143243  acc:  0.125\nep: 4  bt: 550  loss: 0.3565334406766025  acc:  0.203125\nep: 4  bt: 600  loss: 0.3985119732943448  acc:  0.203125\nep: 4  bt: 650  loss: 0.45723663676868787  acc:  0.171875\nep: 4  bt: 700  loss: 0.33390339938077057  acc:  0.140625\nep: 4  bt: 750  loss: 0.4698952761563388  acc:  0.125\nep:  4  train acc: 0.17984375  loss: 0.3894163288311524\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<sunilcha>________________', '<सुनीलचा>_____________', '<सुनिलचा>_____________')\nbatch num:  0 val_acc ('<sanghthan>_______________', '<संघठन>_______________', '<संघघन>_______________')\nbatch num:  0 val_acc ('<moler>___________________', '<मोलर>________________', '<मोले>________________')\nbatch num:  0 val_acc ('<tendukheda>______________', '<तेंदूखेड़ा>__________', '<तेंडुुखेड़ा>_________')\nbatch num:  0 val_acc ('<proporty>________________', '<प्रपोर्टी>___________', '<प्रोपोर्टी>__________')\nbatch num:  0 val_acc ('<dingbar>_________________', '<दिंगबर>______________', '<दिंगबर>______________')\nbatch num:  0 val_acc ('<agar>____________________', '<अगर>_________________', '<अगा>_________________')\nbatch num:  0 val_acc ('<chelsea>_________________', '<चेल्सी>______________', '<चेलसस>>______________')\nbatch num:  0 val_acc ('<sharaabiyon>_____________', '<शराबियों>____________', '<शराबियों>____________')\nbatch num:  0 val_acc ('<matric>__________________', '<मैट्रिक>_____________', '<मैट्रिक>_____________')\nbatch num:  0 val_acc ('<yogfal>__________________', '<योगफल>_______________', '<योगफलल>______________')\nbatch num:  0 val_acc ('<darvaja>_________________', '<दरवाजा>______________', '<दरवाजा>______________')\nbatch num:  0 val_acc ('<karta>___________________', '<कर्ता>_______________', '<करता>________________')\nbatch num:  0 val_acc ('<jarj>____________________', '<जार्ज>_______________', '<जर्ज>________________')\nbatch num:  0 val_acc ('<nritya>__________________', '<नृत्य>_______________', '<नृत्या>______________')\nbatch num:  0 val_acc ('<khiryu>__________________', '<खिरयु>_______________', '<खिर्यु>______________')\nbatch num:  0 val_acc ('<bhavnayn>________________', '<भावनाएं>_____________', '<भववाययं>_____________')\nbatch num:  0 val_acc ('<zar>_____________________', '<झर>__________________', '<जार>_________________')\nbatch num:  0 val_acc ('<thela>___________________', '<थैला>________________', '<थेला>________________')\nbatch num:  0 val_acc ('<wawre>___________________', '<वावरे>_______________', '<वावरे>_______________')\naccuracy:  0.2080078125  loss: 0.36124499887228023\n('<poynter>_________________', '<पोयंटर>______________', '<पोयंटर>______________')\n('<telecommuting>___________', '<टेलीकम्युटिंग>_______', '<टेलीकमममटटिं>________')\n('<adhikhari>_______________', '<अधिखारी>_____________', '<अधिखररी>_____________')\n('<iconics>_________________', '<आइकोनिक्स>___________', '<आइकोनिक्स>___________')\n('<istava>__________________', '<इस्तवा>______________', '<इस्तावा>_____________')\n('<occupancy>_______________', '<आक्यूपेंसी>__________', '<ओक्यूपेंसस>__________')\n('<saskati>_________________', '<सस्कति>______________', '<ससस्ति>______________')\n('<chakravata>______________', '<चक्रवता>_____________', '<चक्रवता>_____________')\n('<pedana>__________________', '<पेड़ना>______________', '<पेडाना>______________')\n('<nandkumar>_______________', '<नन्दकुमार>___________', '<नंदकुममर>____________')\n('<dhingumata>______________', '<ढिंगूमाता>___________', '<धिंगुमता>____________')\n('<sajaayen>________________', '<सजायें>______________', '<सजायें>______________')\n('<ranbiranand>_____________', '<रणबीरानंद>___________', '<राबीरननदद>___________')\n('<satuary>_________________', '<सैचुरी>______________', '<सैचुरी>______________')\n('<simbad>__________________', '<सिम्बाड>_____________', '<सिंबाड>______________')\n('<petitions>_______________', '<पिटिशंस>_____________', '<पेटिशनस>_____________')\n('<malshi>__________________', '<माल्शी>______________', '<मलशीी>_______________')\n('<ghumal>__________________', '<घुमल>________________', '<घुमल>________________')\n('<refelov>_________________', '<रेफेलोव>_____________', '<रेफेलोव>_____________')\n('<smartsensor>_____________', '<स्मार्टसेंसर>________', '<स्मार्सेननसर>________')\nep: 5  bt: 0  loss: 0.3241562409834428  acc:  0.25\nep: 5  bt: 50  loss: 0.3191793831911954  acc:  0.234375\nep: 5  bt: 100  loss: 0.3053157329559326  acc:  0.25\nep: 5  bt: 150  loss: 0.35096805745905096  acc:  0.3125\nep: 5  bt: 200  loss: 0.3440313555977561  acc:  0.15625\nep: 5  bt: 250  loss: 0.3086404366926713  acc:  0.234375\nep: 5  bt: 300  loss: 0.33741933649236505  acc:  0.15625\nep: 5  bt: 350  loss: 0.3587559569965709  acc:  0.1875\nep: 5  bt: 400  loss: 0.3084737170826305  acc:  0.25\nep: 5  bt: 450  loss: 0.3647810762578791  acc:  0.203125\nep: 5  bt: 500  loss: 0.35817818208174274  acc:  0.25\nep: 5  bt: 550  loss: 0.3544811552221125  acc:  0.203125\nep: 5  bt: 600  loss: 0.3548113432797519  acc:  0.109375\nep: 5  bt: 650  loss: 0.37143117731267755  acc:  0.25\nep: 5  bt: 700  loss: 0.4172800237482244  acc:  0.203125\nep: 5  bt: 750  loss: 0.38479839671741833  acc:  0.203125\nep:  5  train acc: 0.21751953125  loss: 0.3504836550084027\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<habibunnisa>_____________', '<हबीबुन्निसा>_________', '<हबबबुननििाा>_________')\nbatch num:  0 val_acc ('<manaya>__________________', '<मनाया>_______________', '<मनाया>_______________')\nbatch num:  0 val_acc ('<vidya>___________________', '<विद्या>______________', '<विद्या>______________')\nbatch num:  0 val_acc ('<upamanyu>________________', '<उपमन्यु>_____________', '<उपमानयु>_____________')\nbatch num:  0 val_acc ('<maharajaon>______________', '<महाराजाओं>___________', '<महरराजां>____________')\nbatch num:  0 val_acc ('<viewer>__________________', '<व्यूअर>______________', '<वायवरर_______________')\nbatch num:  0 val_acc ('<pro>_____________________', '<प्रो>________________', '<प्रो>________________')\nbatch num:  0 val_acc ('<babaleshwar>_____________', '<बबलेश्वर>____________', '<बाबेल््रर>___________')\nbatch num:  0 val_acc ('<vodhgaya>________________', '<वोधगया>______________', '<वोधगाया______________')\nbatch num:  0 val_acc ('<kelang>__________________', '<केलांग>______________', '<केलंं>_______________')\nbatch num:  0 val_acc ('<amodh>___________________', '<अमोद>________________', '<अमोध>________________')\nbatch num:  0 val_acc ('<halt>____________________', '<हॉल्ट>_______________', '<हाल्ट>_______________')\nbatch num:  0 val_acc ('<ra>______________________', '<ऋ>___________________', '<रा>>_________________')\nbatch num:  0 val_acc ('<nakronda>________________', '<नकरोंदा>_____________', '<नकरोंडा>_____________')\nbatch num:  0 val_acc ('<dhilapan>________________', '<ढीलापन>______________', '<ढिलापन>______________')\nbatch num:  0 val_acc ('<niraksharata>____________', '<निरक्षरता>___________', '<निरक्षररता>__________')\nbatch num:  0 val_acc ('<dukaane>_________________', '<दुकानें>_____________', '<दुकाने>______________')\nbatch num:  0 val_acc ('<kitani>__________________', '<कितनी>_______________', '<किटानी>______________')\nbatch num:  0 val_acc ('<maratheshahi>____________', '<मराठेशाही>___________', '<मराथेशाही>___________')\nbatch num:  0 val_acc ('<padosipan>_______________', '<पड़ोसीपन>____________', '<पदोसिपनन>____________')\naccuracy:  0.2236328125  loss: 0.35172636806964885\n('<hildebrand>______________', '<हिल्डब्रैंड>_________', '<हिल्डबररंंड__________')\n('<bhavaabhivyakti>_________', '<भवाभिव्यक्ति>________', '<भवाभिव््््ति>________')\n('<cheelon>_________________', '<चीलों>_______________', '<चीलों>_______________')\n('<hukalyane>_______________', '<हुकल्याने>___________', '<हुकल्याने>___________')\n('<sajidul>_________________', '<सजीदुल>______________', '<सजीदुल>______________')\n('<mansabi>_________________', '<मनसबी>_______________', '<मनसाबी>______________')\n('<norodam>_________________', '<नोरोदम>______________', '<नोरोदमम>_____________')\n('<pighaltaa>_______________', '<पिघलता>______________', '<पिघलता>______________')\n('<cordaid>_________________', '<कॉरडेड>______________', '<कोर्डडड>_____________')\n('<unauthorised>____________', '<अनआथोराइज्ड>_________', '<अनाथथराइइ््>>________')\n('<santoshdayak>____________', '<संतोषदायक>___________', '<संतोषदायय>___________')\n('<marjoda>_________________', '<मर्जोडा>_____________', '<मारोडाा>_____________')\n('<shompiya>________________', '<शोंपिया>_____________', '<शोमपिया>_____________')\n('<govanditil>______________', '<गोवंडीतील>___________', '<गोवंदीतील>___________')\n('<bharanyasah>_____________', '<भरण्यासह>____________', '<भरण्ययसहह>___________')\n('<tollhouse>_______________', '<टोलहाउस>_____________', '<टोलहहोस>_____________')\n('<hammersmith>_____________', '<हेमरस्मिथ>___________', '<हैम्सममिथ>___________')\n('<baghaghat>_______________', '<बघाघाट>______________', '<बघाघाट>______________')\n('<splander>________________', '<स्प्लैण्डर>__________', '<स्प्लैंरर>___________')\n('<churaaundi>______________', '<चुराऊंदी>____________', '<चुरौनडडी>____________')\nep: 6  bt: 0  loss: 0.2985484383322976  acc:  0.3125\nep: 6  bt: 50  loss: 0.3162307956001975  acc:  0.1875\nep: 6  bt: 100  loss: 0.31690866296941583  acc:  0.28125\nep: 6  bt: 150  loss: 0.24421798099171033  acc:  0.21875\nep: 6  bt: 200  loss: 0.32261532003229315  acc:  0.265625\nep: 6  bt: 250  loss: 0.31847776066173206  acc:  0.25\nep: 6  bt: 300  loss: 0.2717906561764804  acc:  0.3125\nep: 6  bt: 350  loss: 0.34511769901622424  acc:  0.203125\nep: 6  bt: 400  loss: 0.3042108579115434  acc:  0.3125\nep: 6  bt: 450  loss: 0.24703272906216708  acc:  0.328125\nep: 6  bt: 500  loss: 0.29376478628678754  acc:  0.203125\nep: 6  bt: 550  loss: 0.42493763836947357  acc:  0.171875\nep: 6  bt: 600  loss: 0.32846234061501245  acc:  0.25\nep: 6  bt: 650  loss: 0.3109069520776922  acc:  0.25\nep: 6  bt: 700  loss: 0.350534894249656  acc:  0.234375\nep: 6  bt: 750  loss: 0.31096985123374243  acc:  0.234375\nep:  6  train acc: 0.25708984375  loss: 0.3127904447913171\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<jvaare>__________________', '<ज्वारे>______________', '<ज्वारे>______________')\nbatch num:  0 val_acc ('<madhaval>________________', '<माधवल>_______________', '<मधधवल>_______________')\nbatch num:  0 val_acc ('<upbhoktaon>______________', '<उपभोक्ताओं>__________', '<उपभुक्तओं>___________')\nbatch num:  0 val_acc ('<rashning>________________', '<राशनिंग>_____________', '<राशनंंग>_____________')\nbatch num:  0 val_acc ('<chitrkaron>______________', '<चित्रकारों>__________', '<चित्रकारं>___________')\nbatch num:  0 val_acc ('<prapathe>________________', '<प्रपथे>______________', '<प्रपाठे>_____________')\nbatch num:  0 val_acc ('<teach>___________________', '<टीच>_________________', '<टीक>_________________')\nbatch num:  0 val_acc ('<dhut>____________________', '<धुत>_________________', '<धुत>_________________')\nbatch num:  0 val_acc ('<tangane>_________________', '<टांगने>______________', '<टंगगेने______________')\nbatch num:  0 val_acc ('<varnaa>__________________', '<वर्ना>_______________', '<वरना>________________')\nbatch num:  0 val_acc ('<shaavaka>________________', '<शावक>________________', '<शावका>_______________')\nbatch num:  0 val_acc ('<chaiwallah>______________', '<चायवाला>_____________', '<चैववलललाा>___________')\nbatch num:  0 val_acc ('<shershi>_________________', '<शेरशी>_______________', '<शेरशशी>______________')\nbatch num:  0 val_acc ('<panjabi>_________________', '<पंजाबी>______________', '<पंजाबी>______________')\nbatch num:  0 val_acc ('<kamccha>_________________', '<कमच्छा>______________', '<कामचचा>______________')\nbatch num:  0 val_acc ('<ashoka>__________________', '<अशोका>_______________', '<अशोका>_______________')\nbatch num:  0 val_acc ('<devdaar>_________________', '<देवदार>______________', '<देवडार>______________')\nbatch num:  0 val_acc ('<stallone>________________', '<स्टैलोन>_____________', '<स्टॉलोन>_____________')\nbatch num:  0 val_acc ('<ghuspaithiyan>___________', '<घुसपैठियों>__________', '<घुसपिठियया>__________')\nbatch num:  0 val_acc ('<bhgti>___________________', '<भुगती>_______________', '<भीजीीीई______________')\naccuracy:  0.2216796875  loss: 0.3570822070945394\n('<karegaae>________________', '<करेगाए>______________', '<करेगाए>______________')\n('<possibility>_____________', '<पॉसिबिलटी>___________', '<पोजिबिलिटी___________')\n('<rujlelya>________________', '<रुजलेल्या>___________', '<रुजलेल्या>___________')\n('<shorpshooter>____________', '<शॉर्पशूटर>___________', '<शोर्ोशूटर>___________')\n('<chikitsaashaastra>_______', '<चिकित्साशास्त्र>_____', '<चिकित्सावात्त्र>_____')\n('<boddapati>_______________', '<बोडदापति>____________', '<बोददापति>____________')\n('<lohiyaan>________________', '<लोहियाँ>_____________', '<लोहियां>_____________')\n('<khorbahara>______________', '<खोरबहरा>_____________', '<खोरबारा>_____________')\n('<lalbhai>_________________', '<लालाभाई>_____________', '<लालाई>_______________')\n('<temesi>__________________', '<टेमेसी>______________', '<टेमेसी>______________')\n('<zazai>___________________', '<जज़ाई>_______________', '<ज़़़ा>_______________')\n('<chabukswarwadiche>_______', '<चाबुकस्वारवाडीचे>____', '<चाबुकस्वववववेीी>_____')\n('<dinkaraji>_______________', '<दिनकरजी>_____________', '<दिनकाजी>_____________')\n('<tapoti>__________________', '<तपोती>_______________', '<तपोटी>_______________')\n('<antigonus>_______________', '<आन्तिगोनुस>__________', '<एंटीगोनसस____________')\n('<ritushraav>______________', '<ऋतुश्राव>____________', '<रिुश्ररव>____________')\n('<sheilon>_________________', '<शैलों>_______________', '<शेलों>_______________')\n('<simheshwarapatya>________', '<सिंहेश्वरापत्य>______', '<सिहहेश्वररतत्य>______')\n('<pachanshakti>____________', '<पाचनशक्ति>___________', '<पचचश्कति>____________')\n('<dhuklan>_________________', '<ढुकलान>______________', '<धुकलान>______________')\nep: 7  bt: 0  loss: 0.27192215486006305  acc:  0.25\nep: 7  bt: 50  loss: 0.3171653747558594  acc:  0.3125\nep: 7  bt: 100  loss: 0.22948542508212003  acc:  0.328125\nep: 7  bt: 150  loss: 0.33517549254677514  acc:  0.28125\nep: 7  bt: 200  loss: 0.24325082518837668  acc:  0.40625\nep: 7  bt: 250  loss: 0.2687706080350009  acc:  0.328125\nep: 7  bt: 300  loss: 0.3274669213728471  acc:  0.28125\nep: 7  bt: 350  loss: 0.3032279448075728  acc:  0.359375\nep: 7  bt: 400  loss: 0.2688353278420188  acc:  0.265625\nep: 7  bt: 450  loss: 0.2679120627316562  acc:  0.234375\nep: 7  bt: 500  loss: 0.2796379869634455  acc:  0.359375\nep: 7  bt: 550  loss: 0.33827610449357465  acc:  0.28125\nep: 7  bt: 600  loss: 0.2971364801580256  acc:  0.296875\nep: 7  bt: 650  loss: 0.30187216672030365  acc:  0.328125\nep: 7  bt: 700  loss: 0.3009580265391957  acc:  0.234375\nep: 7  bt: 750  loss: 0.324293851852417  acc:  0.28125\nep:  7  train acc: 0.299765625  loss: 0.27773974596099427\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<vodka>___________________', '<वोडका>_______________', '<वोड़ा>_______________')\nbatch num:  0 val_acc ('<shabe>___________________', '<शबे>_________________', '<शबबे>________________')\nbatch num:  0 val_acc ('<inclination>_____________', '<इनक्लिनेशन>__________', '<इन्कललएेेनन__________')\nbatch num:  0 val_acc ('<aajmaavilyaanantar>______', '<आजमाविल्यानंतर>______', '<आजाााीलययननतर>_______')\nbatch num:  0 val_acc ('<saha>____________________', '<साहा>________________', '<सहा>_________________')\nbatch num:  0 val_acc ('<niraksharata>____________', '<निरक्षरता>___________', '<निरा्षररता>__________')\nbatch num:  0 val_acc ('<upabhoktawaad>___________', '<उपभोक्तावाद>_________', '<उपभूक्तवाद>__________')\nbatch num:  0 val_acc ('<pratispardhayein>________', '<प्रतिस्पर्धाएं>______', '<प्रतिस्परधायें>______')\nbatch num:  0 val_acc ('<earthing>________________', '<अर्थिंग>_____________', '<आयरथिंग>_____________')\nbatch num:  0 val_acc ('<deentao>_________________', '<दीनताओ>______________', '<दीनताओ>______________')\nbatch num:  0 val_acc ('<asamantae>_______________', '<असमानताएं>___________', '<असंमतत>______________')\nbatch num:  0 val_acc ('<edul>____________________', '<एदुल>________________', '<एडुल>________________')\nbatch num:  0 val_acc ('<nitigat>_________________', '<नीतिगत>______________', '<नितिगत>______________')\nbatch num:  0 val_acc ('<nilaambar>_______________', '<नीलांबर>_____________', '<नीलांबरर_____________')\nbatch num:  0 val_acc ('<masudanpur>______________', '<मसुदनपुर>____________', '<मसूदननपरर____________')\nbatch num:  0 val_acc ('<mussels>_________________', '<मसल्स>_______________', '<मससेससस______________')\nbatch num:  0 val_acc ('<piro>____________________', '<पिरो>________________', '<पिरो>________________')\nbatch num:  0 val_acc ('<alagavavaad>_____________', '<अलगाववाद>____________', '<अलगगवााद>____________')\nbatch num:  0 val_acc ('<bhalwal>_________________', '<भालवाल>______________', '<भलवाल>>______________')\nbatch num:  0 val_acc ('<chausath>________________', '<चौंसठ>_______________', '<चौसत>________________')\naccuracy:  0.23876953125  loss: 0.3696950792588971\n('<navelnigari>_____________', '<नावेलनिगारी>_________', '<नवेल्निगरर___________')\n('<sajhee>__________________', '<साझी>________________', '<साझी>________________')\n('<shahvanshiya>____________', '<शाहवंशीय>____________', '<शाहवंशीय_____________')\n('<larampur>________________', '<लरामपुर>_____________', '<लरणमपुर>_____________')\n('<shakunshastra>___________', '<शकुनशास्त्र>_________', '<शकुनशास्त्र__________')\n('<asposita>________________', '<एस्पोसिटा>___________', '<अस्पोििाा____________')\n('<sangamataane>____________', '<संगमताने>____________', '<संगमताने>____________')\n('<kalavatiya>______________', '<कलावटिया>____________', '<कलववटिया>____________')\n('<bourses>_________________', '<बोर्सेज>_____________', '<बोर्सेस______________')\n('<sankochshilta>___________', '<संकोचशीलता>__________', '<संकोचचिलताा>_________')\n('<laurena>_________________', '<लॉरेना>______________', '<लारेना>______________')\n('<patryanchya>_____________', '<पत्र्यांच्या>________', '<पत्र्यांच्या>________')\n('<gavaane>_________________', '<गवाने>_______________', '<गवाने>_______________')\n('<bichon>__________________', '<बिचों>_______________', '<बिचों>_______________')\n('<vocational>______________', '<वोकेशनल>_____________', '<वोकेशनल>_____________')\n('<creekside>_______________', '<क्रीकसाइड>___________', '<क्रीकसाइ>____________')\n('<chumbakatva>_____________', '<चुंबकत्व>____________', '<चुंबकक््व>___________')\n('<certain>_________________', '<सर्टेन>______________', '<सर्टेन>______________')\n('<atimandra>_______________', '<अतिमन्द्र>___________', '<अतिमंद्र>____________')\n('<benisio>_________________', '<बेनिसियो>____________', '<बेनिसियो>____________')\nep: 8  bt: 0  loss: 0.19070896235379306  acc:  0.375\nep: 8  bt: 50  loss: 0.15631027655168014  acc:  0.484375\nep: 8  bt: 100  loss: 0.250980637290261  acc:  0.296875\nep: 8  bt: 150  loss: 0.19778236475857822  acc:  0.453125\nep: 8  bt: 200  loss: 0.24166013977744363  acc:  0.375\nep: 8  bt: 250  loss: 0.30005019361322577  acc:  0.234375\nep: 8  bt: 300  loss: 0.225407058542425  acc:  0.359375\nep: 8  bt: 350  loss: 0.29395222663879395  acc:  0.359375\nep: 8  bt: 400  loss: 0.21570719372142444  acc:  0.40625\nep: 8  bt: 450  loss: 0.2167626510966908  acc:  0.296875\nep: 8  bt: 500  loss: 0.2201167019930753  acc:  0.296875\nep: 8  bt: 550  loss: 0.17008697986602783  acc:  0.390625\nep: 8  bt: 600  loss: 0.2258298397064209  acc:  0.359375\nep: 8  bt: 650  loss: 0.23180751367048782  acc:  0.28125\nep: 8  bt: 700  loss: 0.19395457614551892  acc:  0.453125\nep: 8  bt: 750  loss: 0.3013600002635609  acc:  0.265625\nep:  8  train acc: 0.3405859375  loss: 0.24623125446113675\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<dal>_____________________', '<दल>__________________', '<डल>>_________________')\nbatch num:  0 val_acc ('<jware>___________________', '<ज्वारे>______________', '<ज्वारर>______________')\nbatch num:  0 val_acc ('<keniharak>_______________', '<केनिहारक>____________', '<केनिहारक>____________')\nbatch num:  0 val_acc ('<landibagh>_______________', '<लैंडीबाग>____________', '<लं्डीबाग>____________')\nbatch num:  0 val_acc ('<flat>____________________', '<फॉल्ट>_______________', '<फ्लाट>_______________')\nbatch num:  0 val_acc ('<many>____________________', '<मैनी>________________', '<मैन>>________________')\nbatch num:  0 val_acc ('<moolbhoot>_______________', '<मूलभूत>______________', '<मूलभूत>______________')\nbatch num:  0 val_acc ('<kanchon>_________________', '<कंचों>_______________', '<कांचों>______________')\nbatch num:  0 val_acc ('<mukesh>__________________', '<मुकेश>_______________', '<मुकेश>_______________')\nbatch num:  0 val_acc ('<fantasy>_________________', '<फंतासी>______________', '<फैंटासी>_____________')\nbatch num:  0 val_acc ('<warrior>_________________', '<वारियर>______________', '<वारियर>______________')\nbatch num:  0 val_acc ('<uppal>___________________', '<उप्पल>_______________', '<उपपपल>एए_____________')\nbatch num:  0 val_acc ('<urvarkata>_______________', '<उर्वरकता>____________', '<उर्वरककता>___________')\nbatch num:  0 val_acc ('<sahpal>__________________', '<सहपाल>_______________', '<सहपाल>_______________')\nbatch num:  0 val_acc ('<jayen>___________________', '<जयन>_________________', '<जयने>________________')\nbatch num:  0 val_acc ('<bichukalyancha>__________', '<बिचुकल्यांचा>________', '<बिचुकाल्ांचच>________')\nbatch num:  0 val_acc ('<anmum>___________________', '<अम्मू>_______________', '<अनमुुम_______________')\nbatch num:  0 val_acc ('<kamilo>__________________', '<कैमिलो>______________', '<कामिो>_______________')\nbatch num:  0 val_acc ('<tejsvi>__________________', '<तेजस्वी>_____________', '<तेजस्वी>_____________')\nbatch num:  0 val_acc ('<grider>__________________', '<ग्राइडर>_____________', '<ग्राडर>______________')\naccuracy:  0.245849609375  loss: 0.37414494461633935\n('<gauraha>_________________', '<गौरहा>_______________', '<गौरह>________________')\n('<javi>____________________', '<जावी>________________', '<जावी>________________')\n('<parkingchahi>____________', '<पार्किंगचाही>________', '<पार्किंगचाही>________')\n('<brugada>_________________', '<ब्रुगाडा>____________', '<ब्रुगाडा>____________')\n('<hamerlal>________________', '<हमेरलाल>_____________', '<हमेरलाल>_____________')\n('<tyrosine>________________', '<टायरोसाइन>___________', '<टाइरोसिन>>___________')\n('<hygienist>_______________', '<हाईजिनिस्ट>__________', '<हाइििििस्ट>__________')\n('<daumajra>________________', '<दाउमाजरा>____________', '<दौममजररा>____________')\n('<diwali>__________________', '<दीपावली>_____________', '<दिवाली>______________')\n('<aapiye>__________________', '<आपिये>_______________', '<आपिये>_______________')\n('<genzo>___________________', '<गेंजो>_______________', '<गेंजो>_______________')\n('<ptree>___________________', '<पत्री>_______________', '<पत्री>_______________')\n('<buenis>__________________', '<ब्यूनिस>_____________', '<ब्यूनसस>_____________')\n('<dagaan>__________________', '<दगान>________________', '<दगां>________________')\n('<bishnulal>_______________', '<बिष्णुलाल>___________', '<बिशनुलाल>____________')\n('<antarjalmarg>____________', '<अंतरजलमार्ग>_________', '<अंतरजजममर्ग>_________')\n('<bookels>_________________', '<बुकेल्स>_____________', '<बुकेल्स>_____________')\n('<adhun>___________________', '<अधुन>________________', '<अधुन>________________')\n('<poorvaadesh>_____________', '<पूर्वादेश>___________', '<पूर्वादेश>___________')\n('<yaroo>___________________', '<यरू>_________________', '<यरूू>________________')\nep: 9  bt: 0  loss: 0.21305925195867365  acc:  0.40625\nep: 9  bt: 50  loss: 0.18857416239651767  acc:  0.421875\nep: 9  bt: 100  loss: 0.25732738321477716  acc:  0.34375\nep: 9  bt: 150  loss: 0.24456236579201437  acc:  0.296875\nep: 9  bt: 200  loss: 0.19481942870400168  acc:  0.375\nep: 9  bt: 250  loss: 0.22209436243230646  acc:  0.34375\nep: 9  bt: 300  loss: 0.22120993787592108  acc:  0.421875\nep: 9  bt: 350  loss: 0.2780508344823664  acc:  0.28125\nep: 9  bt: 400  loss: 0.2124465595592152  acc:  0.34375\nep: 9  bt: 450  loss: 0.22184965827248312  acc:  0.3125\nep: 9  bt: 500  loss: 0.1822901205583052  acc:  0.453125\nep: 9  bt: 550  loss: 0.21664198962124911  acc:  0.5\nep: 9  bt: 600  loss: 0.17116570472717285  acc:  0.375\nep: 9  bt: 650  loss: 0.1782536723396995  acc:  0.484375\nep: 9  bt: 700  loss: 0.2540621757507324  acc:  0.40625\nep: 9  bt: 750  loss: 0.2267279408194802  acc:  0.34375\nep:  9  train acc: 0.3804296875  loss: 0.21837417941201828\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<edrei>___________________', '<एद्रेई>______________', '<एडररीई_______________')\nbatch num:  0 val_acc ('<naavikon>________________', '<नाविकों>_____________', '<नाविकों>_____________')\nbatch num:  0 val_acc ('<net>_____________________', '<नेट>_________________', '<नेत>_________________')\nbatch num:  0 val_acc ('<salaahkaron>_____________', '<सलाहकारों>___________', '<सलााककों>____________')\nbatch num:  0 val_acc ('<download>________________', '<डाउनलोड>_____________', '<डाउनलोड>_____________')\nbatch num:  0 val_acc ('<payega>__________________', '<पाएगा>_______________', '<पययगा>_______________')\nbatch num:  0 val_acc ('<solhaven>________________', '<सोलहवें>_____________', '<सोल्हाें>____________')\nbatch num:  0 val_acc ('<vns>_____________________', '<वीनस>________________', '<वीएनएसए>_____________')\nbatch num:  0 val_acc ('<ahsa>____________________', '<अशा>_________________', '<अहसा>________________')\nbatch num:  0 val_acc ('<chhaanakar>______________', '<छानकर>_______________', '<छानकक>_______________')\nbatch num:  0 val_acc ('<swamiyo>_________________', '<स्वामियो>____________', '<स्वामियो>____________')\nbatch num:  0 val_acc ('<choriyo>_________________', '<चोरियों>_____________', '<चोरियो>______________')\nbatch num:  0 val_acc ('<badbadaai>_______________', '<बड़बड़ाई>____________', '<बड़ाड़ा>_____________')\nbatch num:  0 val_acc ('<ticker>__________________', '<टिकर>________________', '<टिकर>________________')\nbatch num:  0 val_acc ('<image>___________________', '<इमेज>________________', '<इमागे>_______________')\nbatch num:  0 val_acc ('<daali>___________________', '<डाली>________________', '<दाली>________________')\nbatch num:  0 val_acc ('<mongolia>________________', '<मंगोलिया>____________', '<मोंगोलिया>___________')\nbatch num:  0 val_acc ('<sansikt>_________________', '<संसिक्त>_____________', '<संसिक्त>_____________')\nbatch num:  0 val_acc ('<aadat>___________________', '<आदत>_________________', '<आदत>_________________')\nbatch num:  0 val_acc ('<ghumaane>________________', '<घूमाने>______________', '<घुमाने>______________')\naccuracy:  0.25732421875  loss: 0.39081249792467465\n('<registrars>______________', '<रजिस्ट्रा>___________', '<रजिस्ट्रार्स>________')\n('<rajaura>_________________', '<राजौरा>______________', '<राजौरा>______________')\n('<girone>__________________', '<गिरोने>______________', '<गिरोन>_______________')\n('<bamenda>_________________', '<बामेंदा>_____________', '<बामेंा>______________')\n('<sadyasthiticha>__________', '<सद्यस्थितीचा>________', '<सद्यस्थितीचा>________')\n('<continues>_______________', '<कंटिन्यूज>___________', '<कंटटशन्ूूज___________')\n('<piest>___________________', '<पिएस्ट>______________', '<पिएस्ट>______________')\n('<upapareeksha>____________', '<उपपरीक्षा>___________', '<उपपरीक्षा>___________')\n('<nishodhaatmak>___________', '<निषेधात्मक>__________', '<निषोधात्मक>__________')\n('<harnaul>_________________', '<हरनौल>_______________', '<हरनौल>_______________')\n('<chandralesh>_____________', '<चंद्रलेश>____________', '<चनद्रललेश>___________')\n('<sahkaareejanon>__________', '<सहकारीजनों>__________', '<सहकारिजजों>__________')\n('<vidvananchya>____________', '<विद्वानांच्या>_______', '<विद्वानाचचयया________')\n('<dolaate>_________________', '<डोलाते>______________', '<दोलाते>______________')\n('<navyakaraniya>___________', '<नव्यकरणीय>___________', '<नव्यकरणीय>___________')\n('<sabiruddin>______________', '<सबीरूद्दीन>__________', '<सबीरुद्दीन>__________')\n('<audentity>_______________', '<आडेंटिटी>____________', '<आडेंटिटी>____________')\n('<shivkasi>________________', '<शिवकासी>_____________', '<शिवकासी>_____________')\n('<buddhaayan>______________', '<बुद्धायन>____________', '<बुद्धायन>____________')\n('<snaayutantuon>___________', '<स्नायुतंतुओं>________', '<स्नायुतततुओं>________')\nep: 10  bt: 0  loss: 0.13929712772369385  acc:  0.5\nep: 10  bt: 50  loss: 0.1526642604307695  acc:  0.546875\nep: 10  bt: 100  loss: 0.20144575292413885  acc:  0.46875\nep: 10  bt: 150  loss: 0.2159790559248491  acc:  0.46875\nep: 10  bt: 200  loss: 0.17399935288862747  acc:  0.4375\nep: 10  bt: 250  loss: 0.21327252821488815  acc:  0.40625\nep: 10  bt: 300  loss: 0.17621342702345413  acc:  0.40625\nep: 10  bt: 350  loss: 0.1673814816908403  acc:  0.453125\nep: 10  bt: 400  loss: 0.18849713152105158  acc:  0.390625\nep: 10  bt: 450  loss: 0.1707231023094871  acc:  0.5\nep: 10  bt: 500  loss: 0.2605261585929177  acc:  0.453125\nep: 10  bt: 550  loss: 0.20206657322970303  acc:  0.421875\nep: 10  bt: 600  loss: 0.21661242571744052  acc:  0.3125\nep: 10  bt: 650  loss: 0.18605145541104404  acc:  0.421875\nep: 10  bt: 700  loss: 0.2610200968655673  acc:  0.375\nep: 10  bt: 750  loss: 0.18063104152679443  acc:  0.46875\nep:  10  train acc: 0.4257421875  loss: 0.19042452161962367\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<batman>__________________', '<बैटमैन>______________', '<बटमैन>_______________')\nbatch num:  0 val_acc ('<dilvae>__________________', '<दिलवाए>______________', '<दिलवाई>______________')\nbatch num:  0 val_acc ('<tvs>_____________________', '<टीवीएस>______________', '<टीवीएस>______________')\nbatch num:  0 val_acc ('<hold>____________________', '<होल्ड>_______________', '<होल्ड्>______________')\nbatch num:  0 val_acc ('<dhundhen>________________', '<ढूंढें>______________', '<ढूंधें>______________')\nbatch num:  0 val_acc ('<damit>___________________', '<दमित>________________', '<दामिट>_______________')\nbatch num:  0 val_acc ('<squating>________________', '<स्क्वॉटिंग>__________', '<स्क्विटिंग>__________')\nbatch num:  0 val_acc ('<shararton>_______________', '<शरारतों>_____________', '<शरारतटंं_____________')\nbatch num:  0 val_acc ('<antioxidant>_____________', '<एंटीऑक्सिडेंट>_______', '<एन्टयक्सिडिं>________')\nbatch num:  0 val_acc ('<narad>___________________', '<नारद>________________', '<नााद>________________')\nbatch num:  0 val_acc ('<setton>__________________', '<सेटों>_______________', '<सेटनन>_______________')\nbatch num:  0 val_acc ('<mutthi>__________________', '<मुट्ठी>______________', '<मुत्ठी>______________')\nbatch num:  0 val_acc ('<eat>_____________________', '<इट>__________________', '<ईएटी>________________')\nbatch num:  0 val_acc ('<parasaad>________________', '<परसाद>_______________', '<परसाद>_______________')\nbatch num:  0 val_acc ('<proporty>________________', '<प्रपोर्टी>___________', '<प्रोपोट्टी>__________')\nbatch num:  0 val_acc ('<tisari>__________________', '<तिसरी>_______________', '<तिसारी>______________')\nbatch num:  0 val_acc ('<skhalit>_________________', '<स्खलित>______________', '<स्खलित>______________')\nbatch num:  0 val_acc ('<sandeep>_________________', '<संदीप>_______________', '<संदीप>_______________')\nbatch num:  0 val_acc ('<crappe>__________________', '<च्रप्पे>_____________', '<क्रैप>_______________')\nbatch num:  0 val_acc ('<najren>__________________', '<नजरें>_______________', '<ना़रनन>______________')\naccuracy:  0.248779296875  loss: 0.4037234474989502\n('<sepika>__________________', '<सेपिक>_______________', '<सेपिक>>______________')\n('<betibandi>_______________', '<बेटीबंदी>____________', '<बेटीबंदी>____________')\n('<pithadhishwaron>_________', '<पीठाधीश्वरों>________', '<पिठाधशश्वरों>________')\n('<mumbaiwalon>_____________', '<मुंबईवालों>__________', '<मुंबईवालों>__________')\n('<haraamazaada>____________', '<हरामज़ादा>___________', '<हरामज़ादा>___________')\n('<sdsap>___________________', '<एसडीएसएपी>___________', '<एसडीएसएपी>___________')\n('<lanek>___________________', '<लानेक>_______________', '<लानेक>_______________')\n('<matkalia>________________', '<मटकालिया>____________', '<मटकालिया>____________')\n('<affloxin>________________', '<एफ्लॉक्सिन>__________', '<अफललेकससिन>__________')\n('<revotron>________________', '<रेवोट्रॉन>___________', '<रेवोट्रोन>___________')\n('<hirahane>________________', '<हीरहने>______________', '<हिरहने>______________')\n('<ramharth>________________', '<रामहर्थ>_____________', '<रामहारथथ>____________')\n('<pithnapur>_______________', '<पिथनापुर>____________', '<पिथनापुर>____________')\n('<kumauka>_________________', '<कुमौका>______________', '<कुमौका>______________')\n('<nrucc>___________________', '<एनआरयूसीसी>__________', '<एनआरयूसीटी>__________')\n('<yojnau>__________________', '<योजनौ>_______________', '<योजनौ>_______________')\n('<apratyayaksh>____________', '<अप्रत्ययक्ष>_________', '<अप्रतययक््ष>_________')\n('<chhupaayaa>______________', '<छुपाया>______________', '<छुपाया>______________')\n('<punarmulyankan>__________', '<पुनर्मूल्यांकन>______', '<पुनर्मूल्यांकन>______')\n('<veergeeton>______________', '<वीरगीतों>____________', '<वीरगितों>____________')\nep: 11  bt: 0  loss: 0.1340237097306685  acc:  0.5\nep: 11  bt: 50  loss: 0.14456419511274857  acc:  0.46875\nep: 11  bt: 100  loss: 0.15034723281860352  acc:  0.46875\nep: 11  bt: 150  loss: 0.12949038635600696  acc:  0.5\nep: 11  bt: 200  loss: 0.13397910378196023  acc:  0.5625\nep: 11  bt: 250  loss: 0.1962787238034335  acc:  0.53125\nep: 11  bt: 300  loss: 0.18468499183654785  acc:  0.515625\nep: 11  bt: 350  loss: 0.14708107168024237  acc:  0.484375\nep: 11  bt: 400  loss: 0.19242514263499866  acc:  0.40625\nep: 11  bt: 450  loss: 0.21997950293801047  acc:  0.328125\nep: 11  bt: 500  loss: 0.19684962792830032  acc:  0.484375\nep: 11  bt: 550  loss: 0.16724820570512253  acc:  0.546875\nep: 11  bt: 600  loss: 0.1771433028307828  acc:  0.421875\nep: 11  bt: 650  loss: 0.17546585473147305  acc:  0.4375\nep: 11  bt: 700  loss: 0.18478454243053088  acc:  0.34375\nep: 11  bt: 750  loss: 0.16508212956515225  acc:  0.453125\nep:  11  train acc: 0.4633203125  loss: 0.16851954437114988\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<shmashil>________________', '<क्षमाशील>____________', '<श्मशिल>______________')\nbatch num:  0 val_acc ('<valter>__________________', '<वॉल्टर>______________', '<वाल्टर>______________')\nbatch num:  0 val_acc ('<vyapakta>________________', '<व्यापकता>____________', '<व्याक्ता>____________')\nbatch num:  0 val_acc ('<nova>____________________', '<नोवा>________________', '<नोवा>________________')\nbatch num:  0 val_acc ('<bastar>__________________', '<बस्तर>_______________', '<बस्तर>_______________')\nbatch num:  0 val_acc ('<kanto>___________________', '<कांटो>_______________', '<काटटो>_______________')\nbatch num:  0 val_acc ('<leakstar>________________', '<लीकस्टार>____________', '<लेक््टर>>____________')\nbatch num:  0 val_acc ('<gandhipeth>______________', '<गांधीपेठ>____________', '<गांधीपे>_____________')\nbatch num:  0 val_acc ('<jaankari>________________', '<जानकारी>_____________', '<जांकारी>_____________')\nbatch num:  0 val_acc ('<prarupon>________________', '<प्रारूपों>___________', '<प्रातुपों>___________')\nbatch num:  0 val_acc ('<bavandar>________________', '<बवंडर>_______________', '<बवंदार>______________')\nbatch num:  0 val_acc ('<khankarmi>_______________', '<खानकर्मी>____________', '<खाककरमी>_____________')\nbatch num:  0 val_acc ('<saleh>___________________', '<सालेह>_______________', '<सललेह>_______________')\nbatch num:  0 val_acc ('<anshbakh>________________', '<अंशबाख>______________', '<अंशबख>_______________')\nbatch num:  0 val_acc ('<navya>___________________', '<नव्य>________________', '<नव््य________________')\nbatch num:  0 val_acc ('<mahotsanav>______________', '<महोत्सनव>____________', '<महोत्सननव>___________')\nbatch num:  0 val_acc ('<arc>_____________________', '<एआरसी>_______________', '<एआरसी>_______________')\nbatch num:  0 val_acc ('<roster>__________________', '<रोस्टर>______________', '<रोस्टर>______________')\nbatch num:  0 val_acc ('<dattatray>_______________', '<दत्तात्रेय>__________', '<दत्तात्य>य___________')\nbatch num:  0 val_acc ('<mantron>_________________', '<मंत्रों>_____________', '<मंत्रों>_____________')\naccuracy:  0.250244140625  loss: 0.4330431114543567\n('<upanidashek>_____________', '<उपनिदशेक>____________', '<उपनिदशेक>____________')\n('<puskara>_________________', '<पुस्कारा>____________', '<पुस्कारा>____________')\n('<doncer>__________________', '<डॉन्सर>______________', '<डॉं्सर>______________')\n('<pratinidhitvamandal>_____', '<प्रतिनिधित्वमंडल>____', '<प्रतिनिदित्ननंडड>>___')\n('<maannevaalonke>__________', '<माननेवालोंके>________', '<मान्ेवालकंके>________')\n('<jhusi>___________________', '<झूसी>________________', '<झूसी>________________')\n('<gumpha>__________________', '<गुंफा>_______________', '<गुंफ>>>______________')\n('<keshishya>_______________', '<केशिष्य>_____________', '<केशिष्य>_____________')\n('<delivered>_______________', '<डिलीवर्ड>____________', '<डिलिवर्ड>____________')\n('<chemisal>________________', '<केमिसल>______________', '<केमिसल>______________')\n('<stellio>_________________', '<स्टेलियो>____________', '<स्टेलियो>____________')\n('<ratnamani>_______________', '<रत्नमणि>_____________', '<रत्नमणि>_____________')\n('<baidarabad>______________', '<बैदराबाद>____________', '<बैदराबाद>____________')\n('<anklav>__________________', '<अंकलव>_______________', '<अंकलव>_______________')\n('<qaradawi>________________', '<करदावी>______________', '<क़दावी>______________')\n('<chhayaprat>______________', '<छायाप्रत>____________', '<छायाप्रत>____________')\n('<susmita>_________________', '<सुस्मिता>____________', '<सुस्मिता>____________')\n('<parivahankadun>__________', '<परिवहनकडून>__________', '<परिवननककून>__________')\n('<faridoon>________________', '<फरिदून>______________', '<फरीदून>______________')\n('<kesodas>_________________', '<केसोदास>_____________', '<केसोदास>_____________')\nep: 12  bt: 0  loss: 0.14109757813540372  acc:  0.46875\nep: 12  bt: 50  loss: 0.13674840060147372  acc:  0.5\nep: 12  bt: 100  loss: 0.16111486608331854  acc:  0.5\nep: 12  bt: 150  loss: 0.1529396880756725  acc:  0.515625\nep: 12  bt: 200  loss: 0.17556012760509143  acc:  0.484375\nep: 12  bt: 250  loss: 0.13402606140483508  acc:  0.46875\nep: 12  bt: 300  loss: 0.16792239926078104  acc:  0.453125\nep: 12  bt: 350  loss: 0.14956271648406982  acc:  0.46875\nep: 12  bt: 400  loss: 0.17762717333706943  acc:  0.4375\nep: 12  bt: 450  loss: 0.1412303772839633  acc:  0.5\nep: 12  bt: 500  loss: 0.1536221612583507  acc:  0.5\nep: 12  bt: 550  loss: 0.14482049508528275  acc:  0.546875\nep: 12  bt: 600  loss: 0.17266090349717575  acc:  0.40625\nep: 12  bt: 650  loss: 0.1956939480521462  acc:  0.4375\nep: 12  bt: 700  loss: 0.15166262063113126  acc:  0.5\nep: 12  bt: 750  loss: 0.19270014762878418  acc:  0.4375\nep:  12  train acc: 0.49888671875  loss: 0.15110267009247422\n64\n4096\n<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nbatch num:  0 val_acc ('<kala>____________________', '<काला>________________', '<काल>_________________')\nbatch num:  0 val_acc ('<botham>__________________', '<बॉथम>________________', '<बोतमम>_______________')\nbatch num:  0 val_acc ('<stritv>__________________', '<स्त्रीत्व>___________', '<स्त्रित्व>___________')\nbatch num:  0 val_acc ('<naksalvadi>______________', '<नक्सलवादी>___________', '<नकसालवाीी>___________')\nbatch num:  0 val_acc ('<salwar>__________________', '<सलवार>_______________', '<सललवर>_______________')\nbatch num:  0 val_acc ('<fabric>__________________', '<फैब्रिक>_____________', '<फैब्रिक>_____________')\nbatch num:  0 val_acc ('<riders>__________________', '<राइडर्स>_____________', '<राइड्स>______________')\nbatch num:  0 val_acc ('<kaushik>_________________', '<कौशिक>_______________', '<कौशिक>_______________')\nbatch num:  0 val_acc ('<mazedaar>________________', '<मज़ेदार>_____________', '<मज़ेेरर>_____________')\nbatch num:  0 val_acc ('<soman>___________________', '<सोमन>________________', '<सोमन>________________')\nbatch num:  0 val_acc ('<anubhavahin>_____________', '<अनुभवहीन>____________', '<अनुभववीं>____________')\nbatch num:  0 val_acc ('<manjilon>________________', '<मंजिलों>_____________', '<मंंलिलों>____________')\nbatch num:  0 val_acc ('<sajila>__________________', '<सजीला>_______________', '<सजीला>_______________')\nbatch num:  0 val_acc ('<mantron>_________________', '<मंत्रों>_____________', '<मन्त्रोन>____________')\nbatch num:  0 val_acc ('<gadhwana>________________', '<गढ़वाना>_____________', '<गढ़वाना>_____________')\nbatch num:  0 val_acc ('<sadasyaanmadheel>________', '<सदस्यांमधील>_________', '<सदस्यांमधील>_________')\nbatch num:  0 val_acc ('<faalna>__________________', '<फालना>_______________', '<फालना>_______________')\nbatch num:  0 val_acc ('<koruda>__________________', '<कुरोदा>______________', '<कोरूडा>______________')\nbatch num:  0 val_acc ('<pujeet>__________________', '<पुजीत>_______________', '<पूजीत>_______________')\nbatch num:  0 val_acc ('<drashyo>_________________', '<द्रश्यो>_____________', '<द्रश्यो>_____________')\naccuracy:  0.25  loss: 0.4469273364679379\n('<bhikhmanga>______________', '<भिखमंगा>_____________', '<भिखमंगा>_____________')\n('<bhaktiana>_______________', '<भक्तियाना>___________', '<भक्तियाना>___________')\n('<dangkala>________________', '<दांगकला>_____________', '<डांगकााा_____________')\n('<khanum>__________________', '<खानम>________________', '<खनुमुम>______________')\n('<nnef>____________________', '<एनएनईएफ>_____________', '<एनएनईएफ>_____________')\n('<vishwayatra>_____________', '<विश्वयात्रा>_________', '<विश्वयात्रा>_________')\n('<upasthitaanpaiki>________', '<उपस्थितांपैकी>_______', '<उपस्थितांकैकी>_______')\n('<adhimanya>_______________', '<अधिमान्य>____________', '<अधिमा््य>____________')\n('<intersteller>____________', '<इंटरस्टेल्लर>________', '<इनटरस्टटल्लर>________')\n('<diploy>__________________', '<डिप्लाय>_____________', '<डिप्लाय>_____________')\n('<sarvasanmateene>_________', '<सर्वसंमतीने>_________', '<सर्वसंममीनेे>________')\n('<brajvasiyon>_____________', '<ब्रजवासियों>_________', '<ब्रजवासिययों>________')\n('<sahayakpadi>_____________', '<सहायकपदी>____________', '<सहयककपदी>____________')\n('<suteerth>________________', '<सुतीर्थ>_____________', '<सुतीर्थ>_____________')\n('<baghnath>________________', '<बाघनाथ>______________', '<बाघनाथ>______________')\n('<maroj>___________________', '<मरोज>________________', '<मरोज>________________')\n('<cleveland>_______________', '<क्लीवलेंड>___________', '<क्लीवलैंड>___________')\n('<bhangeshwarnath>_________', '<भंगेश्वरनाथ>_________', '<भंगेश्वरनाथ>_________')\n('<alain>___________________', '<अलैन>________________', '<अलैन>________________')\n('<acceptibility>___________', '<एक्सेप्टिबिलिटी>_____', '<एक्सेप्टिबिलिटी>_____')\nep: 13  bt: 0  loss: 0.10893457586115057  acc:  0.609375\nep: 13  bt: 50  loss: 0.1068148829720237  acc:  0.65625\nep: 13  bt: 100  loss: 0.1200243126262318  acc:  0.578125\nep: 13  bt: 150  loss: 0.119815317067233  acc:  0.640625\nep: 13  bt: 200  loss: 0.13125740398060193  acc:  0.421875\nep: 13  bt: 250  loss: 0.13885996558449484  acc:  0.5625\nep: 13  bt: 300  loss: 0.13401052084836093  acc:  0.546875\nep: 13  bt: 350  loss: 0.14530768177726053  acc:  0.546875\nep: 13  bt: 400  loss: 0.10072329911318692  acc:  0.734375\nep: 13  bt: 450  loss: 0.09079265594482422  acc:  0.640625\n","output_type":"stream"}]},{"cell_type":"code","source":"#Run this cell to train a model for a h_params configuration\nconfig = h_params\ntraining_data = prepare_data(config)\nrun = wandb.init(project=\"DL Assignment 2\", name=f\"{config['actv_func']}_ep_{config['epochs']}_lr_{config['learning_rate']}_init_fltr_cnt_{config['num_of_filter']}_fltr_sz_{config['filter_size']}_fltr_mult_{config['filter_multiplier']}_data_aug_{config['data_augumentation']}_batch_norm_{config['batch_normalization']}_dropout_{config['dropout']}_dense_size_{config['dense_layer_size']}\", config=config)\ntrain(config, training_data) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run this cell to run a sweep with appropriate parameters\nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DL assn 2 sweep',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'val_accuracy',\n    },\n    'parameters' : {\n        'epochs':{'values' : [10]},\n        'learning_rate':{'values' : [0.0001, 0.001]},\n        'batch_size':{'values':[32,64]},\n        'num_of_filter':{'values' : [16,32,64] } ,\n        'filter_size':{'values' : [[3,3,3,3,3], [5,5,5,5,5], [7,7,7,7,7], [11,9,7,5,3], [3,5,7,9,11]]},\n        'actv_func':{'values':['elu','gelu','leaky_relu','selu']},\n        'filter_multiplier':{'values' : [1,2]},\n        'data_augumentation':{'values': [ False]},\n        'batch_normalization':{'values' : [True, False]},\n        'dropout':{'values': [0,0.1,0.2]},\n        'dense_layer_size':{'values' : [64, 128,256]},\n        'conv_layers':{'values':[5]}\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_params, project=\"DL Assignment 2\")\ndef main():\n    wandb.init(project=\"DL Assignment 2\" )\n    config = wandb.config\n    with wandb.init(project=\"DL Assignment 2\", name=f\"{config['actv_func']}_ep_{config['epochs']}_lr_{config['learning_rate']}_init_fltr_cnt_{config['num_of_filter']}_fltr_sz_{config['filter_size']}_fltr_mult_{config['filter_multiplier']}_data_aug_{config['data_augumentation']}_batch_norm_{config['batch_normalization']}_dropout_{config['dropout']}_dense_size_{config['dense_layer_size']}_batch_size_{config['batch_size']}\", config=config ):\n        training_data = prepare_data(config)  \n        train(config,training_data)\nwandb.agent(sweep_id, function=main, count=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}